{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "pacific-austin",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "신예린님 깃허브 참고함.\n",
    "https://github.com/rinrin528/AIFFEL-Exploration/blob/main/%5BE-18%5D%20Compare%20OCR%20Libraries.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arranged-railway",
   "metadata": {},
   "source": [
    "# OCR 라이브러리 비교하기\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ethical-responsibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "import cv2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as img\n",
    "\n",
    "# keras-ocr\n",
    "import keras_ocr\n",
    "\n",
    "# tesseract\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "from pytesseract import Output\n",
    "import re\n",
    "\n",
    "# Google OCR API\n",
    "from google.cloud import vision\n",
    "import io\n",
    "from PIL import ImageDraw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seeing-falls",
   "metadata": {},
   "source": [
    "# Step1. 검증용 데이터셋 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "perceived-gravity",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.getenv('HOME')+'/aiffel/enode18/ocr_python/tea/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "isolated-charger",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_path = glob.glob(data_path+\"*.jpg\")\n",
    "images_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "offshore-diving",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 15))\n",
    "\n",
    "for i, image in enumerate(images_path,1):\n",
    "    plt.subplot(5, 3, i)\n",
    "    plt.imshow(img.imread(image))\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "large-microphone",
   "metadata": {},
   "source": [
    "# Step2. Google OCR API, keras-ocr, Tesseract로 테스트 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "domestic-rochester",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras-ocr이 detector과 recognizer를 위한 모델을 자동으로 다운로드받게 됩니다. \n",
    "pipeline = keras_ocr.pipeline.Pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boolean-subdivision",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = [keras_ocr.tools.read(im) for im in images_path]\n",
    "predictions = [pipeline.recognize([im]) for im in images_path]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "close-laugh",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(5, 3, figsize=(30, 30))\n",
    "for a in range(len(axs)):\n",
    "    for b in range(len(axs[a])):\n",
    "        keras_ocr.tools.drawAnnotations(image=images[3*a+b], \n",
    "                                    predictions=predictions[3*a+b][0], ax=axs[a,b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baking-export",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_box(image_path):\n",
    "    filename = os.path.basename(image_path)\n",
    "    # read the image and get the dimensions\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    d = pytesseract.image_to_data(img, output_type=Output.DICT)\n",
    "    n_boxes = len(d['text'])\n",
    "\n",
    "    # draw the bounding boxes on the image\n",
    "    for i in range(n_boxes):\n",
    "        if int(d['conf'][i]) > 1: # confidence가 1 이상인 값들만\n",
    "            (x, y, w, h) = (d['left'][i], d['top'][i], d['width'][i], d['height'][i])\n",
    "            img = cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "            text = d['text'][i]\n",
    "            text = \"\".join([c if ord(c) < 128 else \"\" for c in text]).strip()\n",
    "            cv2.putText(img, text, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                        1.5, (0, 0, 255), 3)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "straight-attendance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# confidence = 1\n",
    "plt.figure(figsize=(15, 15))\n",
    "for i,image_path in enumerate(images_path,1):\n",
    "    img = detect_box(image_path)\n",
    "    plt.subplot(5, 3, i)\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advanced-state",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text(image_path):\n",
    "    custom_oem_psm_config = r'--oem 3 --psm 11'\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    txt = pytesseract.image_to_string(img, lang='eng',config=custom_oem_psm_config)\n",
    "    txt = re.sub(r\"\\n+\",\" \",txt)\n",
    "    return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wicked-spice",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_text(images_path[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optional-discharge",
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_path in images_path:\n",
    "    filename = os.path.basename(image_path)\n",
    "    txt = extract_text(image_path)\n",
    "    txt = \"\".join([c if ord(c) < 128 else \"\" for c in txt]).strip()\n",
    "    print(f'========{filename}========')\n",
    "    print(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "large-cooler",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_text(path):\n",
    "    \"\"\"Detects text in the file.\"\"\"\n",
    "    text_dec = []\n",
    "    bounds = []\n",
    "    client = vision.ImageAnnotatorClient()\n",
    "    \n",
    "    with io.open(path, 'rb') as image_file:\n",
    "        content = image_file.read()\n",
    "    \n",
    "    name = os.path.basename(path)\n",
    "    \n",
    "    image = vision.Image(content=content)\n",
    "\n",
    "    response = client.text_detection(image=image)\n",
    "    texts = response.text_annotations\n",
    "\n",
    "    for text in texts:\n",
    "        text_dec.append(text.description.replace('\\n',''))\n",
    "        vertices = text.bounding_poly\n",
    "        bounds.append(vertices)\n",
    "    \n",
    "    if response.error.message:\n",
    "        raise Exception(\n",
    "            '{}\\nFor more info on error messages, check: '\n",
    "            'https://cloud.google.com/apis/design/errors'.format(\n",
    "                response.error.message))\n",
    "        \n",
    "    return name, text_dec, bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oriental-transmission",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_boxes(image, bounds, color):\n",
    "    \"\"\"Draw a border around the image using the hints in the vector list.\"\"\"\n",
    "    draw = ImageDraw.Draw(image)\n",
    "\n",
    "    for bound in bounds:\n",
    "        draw.polygon([\n",
    "            bound.vertices[0].x, bound.vertices[0].y,\n",
    "            bound.vertices[1].x, bound.vertices[1].y,\n",
    "            bound.vertices[2].x, bound.vertices[2].y,\n",
    "            bound.vertices[3].x, bound.vertices[3].y], None, color)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "australian-honduras",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -l $GOOGLE_APPLICATION_CREDENTIALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "received-logistics",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] =  os.getenv('HOME')+'/aiffel/enode18/ocr_python/hopeful-flash-326517-995a4ddfc997.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "innocent-newsletter",
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in images_path:\n",
    "    detect_text(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "other-memory",
   "metadata": {},
   "outputs": [],
   "source": [
    "ocr_img = []\n",
    "ocr_dict = {}\n",
    "# 위에서 정의한 OCR API 이용 함수를 호출해 봅시다.\n",
    "for path in images_path:\n",
    "    name, text_dec, bounds = detect_text(path)\n",
    "    ocr_dict[name] = text_dec\n",
    "    image = Image.open(path)\n",
    "    draw_boxes(image, bounds, 'red')\n",
    "    ocr_img.append(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stable-order",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 15))\n",
    "\n",
    "for i, img in enumerate(ocr_img, 1):\n",
    "    plt.subplot(5, 3, i)\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deadly-geneva",
   "metadata": {},
   "source": [
    "# Step3. 테스트 결과 정리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latest-spouse",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_keras(num):\n",
    "    keras_ocr.tools.drawAnnotations(image=images[num], predictions=predictions[num][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "anonymous-directory",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_keras(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broke-rapid",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_keras(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "synthetic-participant",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_keras(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subjective-success",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_keras(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continental-garbage",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_keras(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "double-embassy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_tesseract(num):\n",
    "    plt.figure(figsize=(15, 15))\n",
    "\n",
    "    plt.subplot(121)\n",
    "    org = cv2.imread(images_path[num])\n",
    "    org = cv2.cvtColor(org, cv2.COLOR_BGR2RGB)\n",
    "    plt.imshow(org)\n",
    "    plt.title('Original')\n",
    "    plt.subplot(122)\n",
    "    img = detect_box(images_path[num])\n",
    "    plt.imshow(img)\n",
    "    plt.title('Detected')\n",
    "    txt = extract_text(images_path[num])\n",
    "    print(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quantitative-particular",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_tesseract(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "identified-motor",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_tesseract(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "detected-honor",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_tesseract(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "structured-atlas",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_tesseract(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fantastic-stadium",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_google(num):\n",
    "    name, text_dec, bounds = detect_text(images_path[num])\n",
    "    image = Image.open(images_path[num])\n",
    "    \n",
    "    plt.figure(figsize=(15, 15))\n",
    "    plt.subplot(121)\n",
    "    org = image\n",
    "    plt.imshow(org)\n",
    "    plt.title('Original')\n",
    "    plt.subplot(122)\n",
    "    img = draw_boxes(image, bounds, 'red')\n",
    "    plt.imshow(img)\n",
    "    plt.title('Detected')\n",
    "    print(text_dec[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tropical-portsmouth",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_google(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "speaking-archive",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_google(11)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outer-prague",
   "metadata": {},
   "source": [
    "# Step4. 결과 분석과 결론 제시\n",
    "\n",
    "- 차 케이스 사진으로 제품 정보를 검색해주는 서비스를 위해서는 제품명과 세부 맛에 관련된 텍스트를 정확하게 검출해야한다.\n",
    "- 특수문자 부분은 전처리해서 지울 수 있으니 최대한 많은 텍스트를 인식하는지 여부를 보자. ### 분석 기준\n",
    "1. 브랜드명을 정확히 검출했는지\n",
    "2. 핵심 맛 정보를 정확히 검출했는지\n",
    "3. 티백 개수, 무게 등 상세 정보를 검출했는지\n",
    "\n",
    "이미지\tkeras-ocr\ttesseract\tGoogle OCR API\n",
    "0\to/o/o\tx/x/x\to/o/o\n",
    "1\tx/o/o\tx/x/x\to/o/o\n",
    "2\to/o/o\tx/x/o\to/o/o\n",
    "3\to/x/o\tx/o/x\to/o/o\n",
    "4\tx/o/x\tx/o/x\to/o/o\n",
    "5\to/o/o\tx/x/x\to/o/o\n",
    "6\to/o/x\tx/o/x\to/o/o\n",
    "7\tx/o/x\tx/x/x\to/o/o\n",
    "8\to/o/o\to/x/x\to/o/o\n",
    "9\to/o/o\tx/x/x\to/o/o\n",
    "10\to/o/o\tx/x/x\to/o/o\n",
    "11\to/o/o\tx/o/x\to/o/o\n",
    "12\to/o/o\tx/o/x\to/o/o\n",
    "13\to/x/x\tx/x/x\to/o/o\n",
    "14\to/o/o\to/o/o\to/o/o\n",
    "\n",
    "- Google OCR API의 결과가 월등히 우수했다.\n",
    "- tesseract는 사용하기 어려운 수준의 정확도를 보였다.\n",
    "- 비용이 걱정된다면 keras-ocr로 적당히 타협을 보는 것도 좋은 대안일 것이다.\n",
    "\n",
    "- 서비스가 고도의 정확도를 요구하다면 Google OCR API를 사용할 것이고, 비용 절감이 더 우선인 경우 keras-ocr을 사용하는 것이 적합해 보인다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efficient-guarantee",
   "metadata": {},
   "source": [
    "# 회고\n",
    "\n",
    "- 분석을 되게 치밀하게 잘 하셔서 보는 내내 놀랬다.\n",
    "- 하지만 여전히 나는 이해를 못했다.\n",
    "- 파이썬에 대한 개념이 정확하게 안잡혀서 그런가, 알고리즘에 대한 내용이 안잡혀서 그런가 너무나도 먼 산일뿐.\n",
    "- 별사탕 프로젝트로 회생하기를 바랄뿐이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electric-trinity",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heard-mason",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comparative-chapel",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "understood-membership",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "floppy-porcelain",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conscious-trail",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quarterly-spotlight",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
